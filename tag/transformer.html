<!DOCTYPE html>
<html lang="zh-cn">

<head>
  <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />


  <title>Tag Transformer - Leo’s blog</title>


  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="referrer" content="origin" />
  <meta name="generator" content="Pelican" />
<link href="https://leonis.cc/tag/transformer.html" rel="canonical" />
  <!-- Feed -->
  <link href="https://leonis.cc/feed.xml" type="application/atom+xml" rel="alternate"
    title="Leo’s blog Full Atom Feed" />

  <link href="https://leonis.cc/theme/css/style.css" type="text/css" rel="stylesheet" />

  <!-- CSS specified by the user -->


  <link href="https://leonis.cc/theme/css/customize.css" type="text/css" rel="stylesheet" />


  <link href="https://leonis.cc/theme/css/plugins.css" type="text/css" rel="stylesheet" />


  <link href="https://leonis.cc/theme/css/lightgallery.min.css" type="text/css" rel="stylesheet" />


  <link href="https://leonis.cc/theme/css/bookshelf.css" type="text/css" rel="stylesheet" />


  <!-- font-awesome icons -->
  <link href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/font-awesome/6.0.0/css/all.min.css" rel="stylesheet" />
  <!-- Custom fonts -->
  <link href="https://ik.imagekit.io/leonis/ChiuKongGothic-CL-w4/result.css?updatedAt=1700222744424" rel="stylesheet" />
  <link href="https://ik.imagekit.io/leonis/ChiuKongGothic-CL-w5/result.css?updatedAt=1700275749020" rel="stylesheet" />
  <link href="https://ik.imagekit.io/leonis/ChiuKongGothic-CL-w7/result.css?updatedAt=1700275854743" rel="stylesheet" />
  <link href="https://cdnjs.loli.net/ajax/libs/fontsource-fira-sans/5.0.19/400.min.css" rel="stylesheet" />
  <link href="https://cdnjs.loli.net/ajax/libs/fontsource-fira-sans/5.0.19/400-italic.min.css" rel="stylesheet" />
  <link href="https://cdnjs.loli.net/ajax/libs/fontsource-fira-sans/5.0.19/500.min.css" rel="stylesheet" />
  <link href="https://cdnjs.loli.net/ajax/libs/fontsource-fira-sans/5.0.19/500-italic.min.css" rel="stylesheet" />
  <link href="https://cdnjs.loli.net/ajax/libs/fontsource-fira-sans/5.0.19/700.min.css" rel="stylesheet" />
  <link href="https://cdnjs.loli.net/ajax/libs/fontsource-fira-sans/5.0.19/700-italic.min.css" rel="stylesheet" />
  <link href="https://cdnjs.loli.net/ajax/libs/fontsource-lato/5.0.19/400.min.css" rel="stylesheet" />
  <link href="https://ik.imagekit.io/leonis/AdvocateAncientSerifSC-Bold/result.css?updatedAt=1700289637334" rel="stylesheet" />

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->

  <script>
    var siteUrl = 'https://leonis.cc';
  </script>

  <script>
    var localTheme = localStorage.getItem('attila_theme');
    switch (localTheme) {
      case 'dark':
        document.documentElement.classList.add('theme-dark');
        break;
      case 'light':
        document.documentElement.classList.add('theme-light');
        break;
      default:
        break;
    }
  </script>





</head>









<body class="tag-template">

<div class="nav-header">
  <nav class="nav-wrapper" aria-label="Main">
<ul>

    <li class="nav-Home " role="presentation"><a href="/"><span>Home</span></a></li>
    <li class="nav-碎碎唸 " role="presentation"><a href="/category/sui-sui-nian.html"><span>碎碎唸</span></a></li>
    <li class="nav-故紙堆 " role="presentation"><a href="/category/gu-zhi-dui.html"><span>故紙堆</span></a></li>
    <li class="nav-在路上 " role="presentation"><a href="/category/zai-lu-shang.html"><span>在路上</span></a></li>
    <li class="nav-山牆邊 " role="presentation"><a href="/pages/shan-qiang-bian.html"><span>山牆邊</span></a></li>
    <li class="nav-破櫥簏 " role="presentation"><a href="https://neodb.social/users/Leo/"><span>破櫥簏</span></a></li>
    <li class="nav-Archives " role="presentation"><a href="/archives.html"><span>Archives</span></a></li>
    <li class="nav-Tags " role="presentation"><a href="/tags.html"><span>Tags</span></a></li>
    <li class="nav-About " role="presentation"><a href="/about.html"><span>About</span></a></li>

</ul>
<ul class="nav-meta">
    <li class="nav-search">
      <a aria-label="Search" href="/search.html" target="_blank">
        <i class="icon icon-search" aria-hidden="true"></i>
    <span>search</span></a></li>
    <li class="nav-foreverblog">
      <a aria-label="Foreverblog" href="https://www.foreverblog.cn/go.html" target="_blank">
        <i aria-hidden="true"><img src="https://img.foreverblog.cn/wormhole_2_tp.gif" alt="foreverblog" title="穿梭虫洞-随机访问十年之约友链博客"></i>
    <span>foreverblog</span></a></li>
    <li class="nav-travellings">
      <a aria-label="Travellings" href="https://www.travellings.cn/go.html" target="_blank">
        <i aria-hidden="true"><img src="https://www.travellings.cn/assets/w.png" alt="travellings" title="开往-友链接力" aria-hidden="true"></i>
    <span>travellings</span></a></li>
  <li class="nav-search" style="display: none;">
    <a title="Search">
      <i class="icon icon-search" aria-hidden="true"></i>
      <span>Search</span>
    </a>
  </li>
</ul>  </nav>

  <div class="nav-wrapper-control">
    <div class="inner">
      <a class="nav-menu" role="button"><i class="icon icon-menu" aria-hidden="true"></i>Menu</a>
      <a class="nav-search" title="Search" role="button" style="display: none;"><i class="icon icon-search" aria-hidden="true"></i></a>
    </div>
  </div>
</div>
<div class="nav-close" role="button" aria-label="Close"></div>
  <section id="wrapper" class="page-wrapper">
    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header class="blog-header  has-cover ">
      <div class="inner">
        <div class="archive archive-tag box archive-box">
          <span class="archive-info">
            <span class="archive-type">Tag</span>
            <span class="archive-count">
            14 Posts
            </span>
          </span>
          <h2 class="archive-title">Transformer</h2>
        </div>

          <div class="blog-cover cover">
            <img src="https://img.leonis.cc/bg/header.webp" alt="Tag Transformer" />
          </div>
      </div>
    </header>

<div id="index" class="container">
  <main class="content" role="main">
    <div class="extra-pagination">
<nav class="pagination" aria-label="Pagination" role="pagination">
  <div class="inner">
    <div class="box pagination-box">
      <span class="pagination-info">Page 1 of 2</span>
      <a title="Older Posts" class="pagination-prev" href="https://leonis.cc/tag/transformer2.html"><span class="pagination-label">Older Posts</span> <i class="icon icon-arrow-right"></i></a>
    </div>
  </div>
</nav>
    </div>



    <article class="post">
        <div class="inner">
            <div class="box post-box">
                <h2 class="post-title"><a href="https://leonis.cc/sui-sui-nian/2023-06-23-summary-doi.org/10.1038/s42256-023-00647-z.html" rel="bookmark" title="Permalink to 文献总结｜结构诱导的预训练">文献总结｜结构诱导的预训练</a>
                </h2>
                <span class="post-meta">
                        <a class="post-meta-tag" href="https://leonis.cc/author/leo.html">Leo</a>
                     | <time datetime="2023年 6月23日">2023年 6月23日</time>
                     | Archived in 
                    <a class="post-meta-tag" href="https://leonis.cc/category/sui-sui-nian.html">碎碎念</a>
                </span>
                <p class="post-excerpt">
                        本文介绍于 2023 年 MIT 研究团队在 Nature Machine Intelligence 发表上的一篇文章，文章原标题为 Structure-inducing pre-training，文章调查了目前广泛应用的多种预训练模型，设计了一种通过图结构在预训练过程中引入显式且深层结构约束的方法。
                </p>

                <div class="post-excerpt">

                    <aside class="post-tags">
<a href="https://leonis.cc/tag/literature-summary.html"># Literature Summary</a><a href="https://leonis.cc/tag/cadd.html"># CADD</a><a href="https://leonis.cc/tag/gnn.html"># GNN</a><a href="https://leonis.cc/tag/transformer.html"># Transformer</a>                    </aside>
                </div>
            </div>
        </div>
    </article>


    <article class="post">
        <div class="inner">
            <div class="box post-box">
                <h2 class="post-title"><a href="https://leonis.cc/sui-sui-nian/2023-05-27-summary-doi.org/10.1038/s42256-023-00639-z.html" rel="bookmark" title="Permalink to 文献总结｜可以同时完成分子语言序列回归和生成的 Regression Transformer">文献总结｜可以同时完成分子语言序列回归和生成的 Regression Transformer</a>
                </h2>
                <span class="post-meta">
                        <a class="post-meta-tag" href="https://leonis.cc/author/leo.html">Leo</a>
                     | <time datetime="2023年 5月27日">2023年 5月27日</time>
                     | Archived in 
                    <a class="post-meta-tag" href="https://leonis.cc/category/sui-sui-nian.html">碎碎念</a>
                </span>
                <p class="post-excerpt">
                        本文介绍于 2023 年 IBM 研究团队发表在 Nature Machine Intelligence 上的一篇文章，文章原标题为 Regression Transformer enables concurrent sequence regression and generation for molecular language modelling，文章提出了一种可以同时处理序列中的数值与文本并完成回归与生成的多任务的 Transformer 模型。
                </p>

                <div class="post-excerpt">

                    <aside class="post-tags">
<a href="https://leonis.cc/tag/literature-summary.html"># Literature Summary</a><a href="https://leonis.cc/tag/cadd.html"># CADD</a><a href="https://leonis.cc/tag/transformer.html"># Transformer</a>                    </aside>
                </div>
            </div>
        </div>
    </article>


    <article class="post">
        <div class="inner">
            <div class="box post-box">
                <h2 class="post-title"><a href="https://leonis.cc/sui-sui-nian/2023-04-28-summary-doi.org/10.1021/acs.jcim.2c01618.html" rel="bookmark" title="Permalink to 文献总结｜我们能用 Transformer 模型快速学会「翻译」活性分子吗？">文献总结｜我们能用 Transformer 模型快速学会「翻译」活性分子吗？</a>
                </h2>
                <span class="post-meta">
                        <a class="post-meta-tag" href="https://leonis.cc/author/leo.html">Leo</a>
                     | <time datetime="2023年 4月28日">2023年 4月28日</time>
                     | Archived in 
                    <a class="post-meta-tag" href="https://leonis.cc/category/sui-sui-nian.html">碎碎念</a>
                </span>
                <p class="post-excerpt">
                        本文介绍于 2023 年发表在 Journal of Chemical Information and Modeling 上的一篇文章，文章原标题为 Can We Quickly Learn to “Translate” Bioactive Molecules with Transformer Models? 文章使用 MMP 数据训练 Transformer，使其生成具有活性的分子，文章结果表明 Transformer 对于未知靶点也能生成活性分子。
                </p>

                <div class="post-excerpt">

                    <aside class="post-tags">
<a href="https://leonis.cc/tag/literature-summary.html"># Literature Summary</a><a href="https://leonis.cc/tag/cadd.html"># CADD</a><a href="https://leonis.cc/tag/transformer.html"># Transformer</a>                    </aside>
                </div>
            </div>
        </div>
    </article>


    <article class="post">
        <div class="inner">
            <div class="box post-box">
                <h2 class="post-title"><a href="https://leonis.cc/sui-sui-nian/2023-04-22-summary-openreview.html" rel="bookmark" title="Permalink to 文献总结｜使用上下文增强的分子表示提升少样本药物发现的效果">文献总结｜使用上下文增强的分子表示提升少样本药物发现的效果</a>
                </h2>
                <span class="post-meta">
                        <a class="post-meta-tag" href="https://leonis.cc/author/leo.html">Leo</a>
                     | <time datetime="2023年 4月22日">2023年 4月22日</time>
                     | Archived in 
                    <a class="post-meta-tag" href="https://leonis.cc/category/sui-sui-nian.html">碎碎念</a>
                </span>
                <p class="post-excerpt">
                        本文介绍于 2023 年发表在 ICLR 2023 上的一篇文章，文章原标题为 Context-enriched molecule representations improve few-shot drug discovery，文章介绍了一种可以用于药物发现的少样本学习模型 MHNfs，MHNfs 通过 Hopfield 网络用上下文数据集少样本的强化分子表示，提升了分子性质预测的准确度。
                </p>

                <div class="post-excerpt">

                    <aside class="post-tags">
<a href="https://leonis.cc/tag/literature-summary.html"># Literature Summary</a><a href="https://leonis.cc/tag/cadd.html"># CADD</a><a href="https://leonis.cc/tag/transformer.html"># Transformer</a>                    </aside>
                </div>
            </div>
        </div>
    </article>


    <article class="post">
        <div class="inner">
            <div class="box post-box">
                <h2 class="post-title"><a href="https://leonis.cc/sui-sui-nian/2023-04-21-transformer-from-scratch.html" rel="bookmark" title="Permalink to 从零起步的 Transformer 与代码拆解">从零起步的 Transformer 与代码拆解</a>
                </h2>
                <span class="post-meta">
                        <a class="post-meta-tag" href="https://leonis.cc/author/leo.html">Leo</a>
                     | <time datetime="2023年 4月21日">2023年 4月21日</time>
                     | Archived in 
                    <a class="post-meta-tag" href="https://leonis.cc/category/sui-sui-nian.html">碎碎念</a>
                </span>
                <p class="post-excerpt">
                        自 Google 的论文 Attention Is All You Need 发布后，几年内涌现了大量基于 Transformer 的模型，俨然形成了 Transformer 横扫人工智能领域的态势。 网络上也出现了大量解读论文或是讲解 Transformer 的文章，其中也不乏许多高水平人工智能从业者的解读。虽然有些可以称得上是高屋建瓴，但 …
                </p>

                <div class="post-excerpt">

                    <aside class="post-tags">
<a href="https://leonis.cc/tag/python.html"># Python</a><a href="https://leonis.cc/tag/pytorch.html"># PyTorch</a><a href="https://leonis.cc/tag/transformer.html"># Transformer</a>                    </aside>
                </div>
            </div>
        </div>
    </article>


    <article class="post">
        <div class="inner">
            <div class="box post-box">
                <h2 class="post-title"><a href="https://leonis.cc/sui-sui-nian/2023-04-06-summary-doi.org/10.1186/s13321-023-00694-z.html" rel="bookmark" title="Permalink to 文献总结｜DrugEx v3：使用基于图 Transformer 的强化学习进行以分子骨架为约束的药物设计">文献总结｜DrugEx v3：使用基于图 Transformer 的强化学习进行以分子骨架为约束的药物设计</a>
                </h2>
                <span class="post-meta">
                        <a class="post-meta-tag" href="https://leonis.cc/author/leo.html">Leo</a>
                     | <time datetime="2023年 4月06日">2023年 4月06日</time>
                     | Archived in 
                    <a class="post-meta-tag" href="https://leonis.cc/category/sui-sui-nian.html">碎碎念</a>
                </span>
                <p class="post-excerpt">
                        本文介绍 2023 年发布在 Journal of Cheminformatics 上的一篇文章，文章原标题为 DrugEx v3: scaffold‑constrained drug design with graph transformer‑based reinforcement learning，文章介绍了使用包括 Transformer 和 LSTM 模型实现以分子骨架为约束的药物设计的方法并对比了使用 SMILES 与图两种方式的分子表示在分子生成中的区别。
                </p>

                <div class="post-excerpt">

                    <aside class="post-tags">
<a href="https://leonis.cc/tag/literature-summary.html"># Literature Summary</a><a href="https://leonis.cc/tag/cadd.html"># CADD</a><a href="https://leonis.cc/tag/transformer.html"># Transformer</a>                    </aside>
                </div>
            </div>
        </div>
    </article>


    <article class="post">
        <div class="inner">
            <div class="box post-box">
                <h2 class="post-title"><a href="https://leonis.cc/sui-sui-nian/2023-03-11-summary-doi.org/10.48550/arXiv.2209.06158.html" rel="bookmark" title="Permalink to 文献总结｜为蛋白质口袋定制分子：用于基于结构药物设计的 Transformer 分子生成方法">文献总结｜为蛋白质口袋定制分子：用于基于结构药物设计的 Transformer 分子生成方法</a>
                </h2>
                <span class="post-meta">
                        <a class="post-meta-tag" href="https://leonis.cc/author/leo.html">Leo</a>
                     | <time datetime="2023年 3月11日">2023年 3月11日</time>
                     | Archived in 
                    <a class="post-meta-tag" href="https://leonis.cc/category/sui-sui-nian.html">碎碎念</a>
                </span>
                <p class="post-excerpt">
                        本文介绍由微软研究团队于 2022 年发布在 arXiv 上的一篇文章，文章原标题为 Tailoring Molecules for Protein Pockets: a Transformer-based Generative Solution for Structured-based Drug Design，文章使用 Transformer 构建了一种能够获取受体 3 维信息的分子生成模型 TamGent，其中分子生成部分使用了预训练模型，避免了训练数据有限的问题。
                </p>

                <div class="post-excerpt">

                    <aside class="post-tags">
<a href="https://leonis.cc/tag/literature-summary.html"># Literature Summary</a><a href="https://leonis.cc/tag/cadd.html"># CADD</a><a href="https://leonis.cc/tag/transformer.html"># Transformer</a><a href="https://leonis.cc/tag/vae.html"># VAE</a>                    </aside>
                </div>
            </div>
        </div>
    </article>


    <article class="post">
        <div class="inner">
            <div class="box post-box">
                <h2 class="post-title"><a href="https://leonis.cc/sui-sui-nian/2023-03-03-summary-doi.org/10.1021/acs.jcim.1c00600.html" rel="bookmark" title="Permalink to 文献总结｜MolGPT：使用 Transformer 解码器模型实现分子生成">文献总结｜MolGPT：使用 Transformer 解码器模型实现分子生成</a>
                </h2>
                <span class="post-meta">
                        <a class="post-meta-tag" href="https://leonis.cc/author/leo.html">Leo</a>
                     | <time datetime="2023年 3月03日">2023年 3月03日</time>
                     | Archived in 
                    <a class="post-meta-tag" href="https://leonis.cc/category/sui-sui-nian.html">碎碎念</a>
                </span>
                <p class="post-excerpt">
                        本文介绍于 2022 年发表在 Journal of Chemical Information and Modeling 上的一篇文章，文章原标题为 MolGPT: Molecular Generation Using a Transformer-Decoder Model，在 GPT 模型已经在自然语言处理领域得到了成功应用的背景下，这篇文章首次将 GPT 模型应用于完成分子生成的任务，实现了分子性质和结构两个方面的优化。
                </p>

                <div class="post-excerpt">

                    <aside class="post-tags">
<a href="https://leonis.cc/tag/literature-summary.html"># Literature Summary</a><a href="https://leonis.cc/tag/cadd.html"># CADD</a><a href="https://leonis.cc/tag/transformer.html"># Transformer</a><a href="https://leonis.cc/tag/gpt.html"># GPT</a>                    </aside>
                </div>
            </div>
        </div>
    </article>


    <article class="post">
        <div class="inner">
            <div class="box post-box">
                <h2 class="post-title"><a href="https://leonis.cc/sui-sui-nian/2023-02-17-summary-doi.org/10.1038/s42256-022-00580-7.html" rel="bookmark" title="Permalink to 文献总结｜通过大规模化学语言表示捕获分子结构和性质">文献总结｜通过大规模化学语言表示捕获分子结构和性质</a>
                </h2>
                <span class="post-meta">
                        <a class="post-meta-tag" href="https://leonis.cc/author/leo.html">Leo</a>
                     | <time datetime="2023年 2月17日">2023年 2月17日</time>
                     | Archived in 
                    <a class="post-meta-tag" href="https://leonis.cc/category/sui-sui-nian.html">碎碎念</a>
                </span>
                <p class="post-excerpt">
                        本文介绍于 2022 年发表在 Nature Machine Intelligence 上的一篇文章，文章原标题为 Large-scale chemical language representations capture molecular structure and properties，文章使用大量来自 PubChem 和 ZINC 的分子训练了基于 Transformer 的化学语言模型，该模型将原始的 SMILES...
                </p>

                <div class="post-excerpt">

                    <aside class="post-tags">
<a href="https://leonis.cc/tag/literature-summary.html"># Literature Summary</a><a href="https://leonis.cc/tag/cadd.html"># CADD</a><a href="https://leonis.cc/tag/transformer.html"># Transformer</a>                    </aside>
                </div>
            </div>
        </div>
    </article>


    <article class="post">
        <div class="inner">
            <div class="box post-box">
                <h2 class="post-title"><a href="https://leonis.cc/sui-sui-nian/2023-02-11-summary-doi.org/10.1186/s13321-021-00497-0.html" rel="bookmark" title="Permalink to 文献总结｜通过深度神经网络捕获化学家的直觉实现分子优化">文献总结｜通过深度神经网络捕获化学家的直觉实现分子优化</a>
                </h2>
                <span class="post-meta">
                        <a class="post-meta-tag" href="https://leonis.cc/author/leo.html">Leo</a>
                     | <time datetime="2023年 2月11日">2023年 2月11日</time>
                     | Archived in 
                    <a class="post-meta-tag" href="https://leonis.cc/category/sui-sui-nian.html">碎碎念</a>
                </span>
                <p class="post-excerpt">
                        本文介绍于 2021 年发表在 Journal of Cheminformatics 上的一篇文章，文章原标题为 Molecular optimization by capturing chemist’s intuition using deep neural networks，文章使用通过 MMP 算法生成的分子对数据和分子性质数据训练了 Transformer 和 seq2seq 等模型，这些模型能够通过结构改造得到具有目标性质的分子。
                </p>

                <div class="post-excerpt">

                    <aside class="post-tags">
<a href="https://leonis.cc/tag/literature-summary.html"># Literature Summary</a><a href="https://leonis.cc/tag/cadd.html"># CADD</a><a href="https://leonis.cc/tag/transformer.html"># Transformer</a><a href="https://leonis.cc/tag/rnn.html"># RNN</a>                    </aside>
                </div>
            </div>
        </div>
    </article>

<nav class="pagination" aria-label="Pagination" role="pagination">
  <div class="inner">
    <div class="box pagination-box">
      <span class="pagination-info">Page 1 of 2</span>
      <a title="Older Posts" class="pagination-prev" href="https://leonis.cc/tag/transformer2.html"><span class="pagination-label">Older Posts</span> <i class="icon icon-arrow-right"></i></a>
    </div>
  </div>
</nav>
  </main>
</div>
    <div class="nav-footer">
      <nav class="nav-wrapper" aria-label="Footer">
        <span class="nav-copy">Leo’s blog &copy; 2024
        </span>
        <span class="nav-credits">



          Published with <a href="https://github.com/getpelican/pelican" rel="nofollow">Pelican</a> &bull; Theme <a href="https://github.com/arulrajnet/attila" rel="nofollow">Attila</a> &bull;
          <a class="menu-item js-theme" href="#" data-system="System theme" data-dark="Dark theme" data-light="Light theme">
            <span class="theme-icon"></span><span class="theme-text">System theme</span>
          </a>
        </span>
      </nav>
    </div>

  </section>

  <script src="https://cdnjs.loli.net/ajax/libs/jquery/3.6.4/jquery.min.js"></script>
  <!-- code highlight -->
  <script src="https://cdnjs.loli.net/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
  <script src="https://cdnjs.loli.net/ajax/libs/highlight.js/11.7.0/languages/django.min.js"></script>
  <script src="https://cdnjs.loli.net/ajax/libs/highlight.js/11.7.0/languages/dockerfile.min.js"></script>
  <script src="https://cdnjs.loli.net/ajax/libs/highlight.js/11.7.0/languages/markdown.min.js"></script>
  <script src="https://cdnjs.loli.net/ajax/libs/highlight.js/11.7.0/languages/nginx.min.js"></script>
  <script src="https://cdnjs.loli.net/ajax/libs/highlight.js/11.7.0/languages/pgsql.min.js"></script>
  <script type="text/javascript" src="https://leonis.cc/theme/js/jquery.fitvids.js"></script>
  <script type="text/javascript" src="https://leonis.cc/theme/js/script.js"></script>

  <!-- lightbox -->
  <script type="text/javascript" src="https://leonis.cc/theme/js/lightgallery.min.js"></script>
  <script type="text/javascript" src="https://leonis.cc/theme/js/lg-zoom.min.js"></script>
  <script>
    var elements = document.getElementsByClassName("lightgallery");
    for(var i=0; i<elements.length; i++) {
       lightGallery(elements[i]);
    }
  </script>
    <!-- umami analytics -->
    <script async defer src="https://analytics.umami.is/script.js" data-website-id="b508982a-f7bf-4c24-a948-8de93b0cb81d"></script>


  <!-- 	The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in article.html, but it needs to be included down here, after jQuery has already loaded. -->
</body>

</html>