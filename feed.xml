<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Leo's blog</title><link href="http://localhost:8000/" rel="alternate"></link><link href="http://localhost:8000/feed.xml" rel="self"></link><id>http://localhost:8000/</id><updated>2022-07-29T00:00:00+08:00</updated><subtitle>A nook to hoard my manuscripts.</subtitle><entry><title>《统计学习方法》第三章</title><link href="http://localhost:8000/blog05.html" rel="alternate"></link><published>2022-07-29T00:00:00+08:00</published><updated>2022-07-29T00:00:00+08:00</updated><author><name>Leo</name></author><id>tag:localhost,2022-07-29:/blog05.html</id><summary type="html">&lt;p&gt;k 近邻法&lt;/p&gt;</summary><content type="html">&lt;h2 id="k-jin-lin-mo-xing"&gt;k 近邻模型&lt;/h2&gt;
&lt;p&gt;k 近邻法将输入实例的特征空间划分为若干子空间，子空间中的若干实例 &lt;span class="math"&gt;\(x_i\)&lt;/span&gt; 同属于 &lt;span class="math"&gt;\(y_i\)&lt;/span&gt; 类别。具体来说，k 近邻法通过在训练集中找到与新输入实例最邻近的 k 个实例，这 k 个实例大部分属于 &lt;span class="math"&gt;\(y_i\)&lt;/span&gt; 类别，就也将新输入实例归属为 &lt;span class="math"&gt;\(y_i\)&lt;/span&gt; 类别。&lt;/p&gt;
&lt;p&gt;&lt;img alt="k近邻模型" src=""/&gt;&lt;/p&gt;
&lt;p&gt;训练集数据为&lt;/p&gt;
&lt;div class="math"&gt;$$
T=\{ (x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N) \}
$$&lt;/div&gt;
&lt;p&gt;其中 &lt;span class="math"&gt;\(x_i\in\mathbf{R}^n\)&lt;/span&gt; 为特征向量，&lt;span class="math"&gt;\(y_i\in\{c_1,c_2,\cdots,c_K\}\)&lt;/span&gt; 为实例类别。k 近邻法根据&lt;em&gt;距离度量&lt;/em&gt;，在包括最邻近的 &lt;span class="math"&gt;\(k\)&lt;/span&gt; 个点的邻域 &lt;span class="math"&gt;\(N_k(x)\)&lt;/span&gt; 中确定 &lt;span class="math"&gt;\(x\)&lt;/span&gt; 的 类别 &lt;span class="math"&gt;\(y\)&lt;/span&gt;：&lt;/p&gt;
&lt;div class="math"&gt;$$y=\arg \max_{c_j}\sum_{x_i\in N_k(x)}I(y_i=c_i),\qquad i=1,2,\cdots,N;\ j=1,2,3,\cdots,K$$&lt;/div&gt;
&lt;p&gt;其中 &lt;span class="math"&gt;\(I\)&lt;/span&gt; 为指示函数，条件为真时为 &lt;span class="math"&gt;\(1\)&lt;/span&gt;，条件为假时为 &lt;span class="math"&gt;\(0\)&lt;/span&gt;。&lt;/p&gt;
&lt;h2 id="ce-lue"&gt;策略&lt;/h2&gt;
&lt;h3 id="ju-chi-du-liang"&gt;距离度量&lt;/h3&gt;
&lt;p&gt;在二维、三维空间中通常使用欧氏距离来衡量两点间的远近关系（相似程度）：&lt;/p&gt;
&lt;div class="math"&gt;$$d=\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}$$&lt;/div&gt;
&lt;div class="math"&gt;$$d=\sqrt{(x_2-x_1)^2+(y_2-y_1)^2+(z_2-z_1)^2}$$&lt;/div&gt;
&lt;p&gt;在 &lt;span class="math"&gt;\(\mathbf{R}^n\)&lt;/span&gt; 空间中，更通常的距离度量是 &lt;span class="math"&gt;\(L_p\)&lt;/span&gt; 距离，&lt;span class="math"&gt;\(L_p\)&lt;/span&gt; 距离是由距离度量的概念通过推广得到的，因此同样具有衡量两点间远近关系（相似程度）的作用。&lt;/p&gt;
&lt;p&gt;设 &lt;span class="math"&gt;\(x_i,x_j\in\mathbf{R}^n\)&lt;/span&gt;，&lt;span class="math"&gt;\(x_i\)&lt;/span&gt; 与 &lt;span class="math"&gt;\(x_j\)&lt;/span&gt; 的 &lt;span class="math"&gt;\(L_p\)&lt;/span&gt; 距离由下式给出：&lt;/p&gt;
&lt;div class="math"&gt;$$L_p(x_i,x_j)=\left(\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)}|^p\right)^{\frac{1}{p}}$$&lt;/div&gt;
&lt;h3 id="fen-lei-ce-lue"&gt;分类策略&lt;/h3&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="碎碎念"></category><category term="《统计学习方法》"></category><category term="机器学习"></category></entry><entry><title>《统计学习方法》第二章</title><link href="http://localhost:8000/blog04.html" rel="alternate"></link><published>2022-07-27T00:00:00+08:00</published><updated>2022-07-27T00:00:00+08:00</updated><author><name>Leo</name></author><id>tag:localhost,2022-07-27:/blog04.html</id><summary type="html">&lt;p&gt;感知机&lt;/p&gt;</summary><content type="html">&lt;h2 id="gan-zhi-ji-mo-xing"&gt;感知机模型&lt;/h2&gt;
&lt;h3 id="ding-yi"&gt;定义&lt;/h3&gt;
&lt;p&gt;感知机是&lt;em&gt;二分类&lt;/em&gt;的&lt;em&gt;线性&lt;/em&gt;分类模型，感知机定义为&lt;/p&gt;
&lt;div class="math"&gt;$$f(x)=\mathrm{sign}(w\cdot x+b)$$&lt;/div&gt;
&lt;div class="math"&gt;$$\begin{equation}
    \mathrm{sign}(x)=
    \begin{cases}
        +1, &amp;amp;x\geqslant 0\\
        -1, &amp;amp;x&amp;lt;0
    \end{cases}
\end{equation}$$&lt;/div&gt;
&lt;p&gt;其中输入 &lt;span class="math"&gt;\(x\in \mathbf{R}^n\)&lt;/span&gt; 表示实例的特征向量，输出 &lt;span class="math"&gt;\(y\in \{+1,-1\}\)&lt;/span&gt;表示实例的类别。模型参数 &lt;span class="math"&gt;\(w\)&lt;/span&gt; 称为权值，参数 &lt;span class="math"&gt;\(b\)&lt;/span&gt; 称为偏置。&lt;/p&gt;
&lt;h3 id="gan-zhi-ji-de-ji-he-mo-xing"&gt;感知机的几何模型&lt;/h3&gt;
&lt;p&gt;若 &lt;span class="math"&gt;\(x\in \mathbf{R}^2\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{align}
    w\cdot x+b&amp;amp;=0\\
    (w^{(1)},w^{(2)})^\mathrm{T}\cdot (x^{(1)},x^{(2)})^\mathrm{T}+b&amp;amp;=0\\
\end{align}$$&lt;/div&gt;
&lt;p&gt;该形式满足平面中的直线方程：&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{align}
    (i,j)^\mathrm{T}\cdot (x^{(1)},x^{(2)})^\mathrm{T}+b&amp;amp;=0\\
    ix^{(1)}+jx^{(2)}+b&amp;amp;=0
\end{align}$$&lt;/div&gt;
&lt;p&gt;其中 &lt;span class="math"&gt;\(w=(i,j)^\mathrm{T}\)&lt;/span&gt; 为直线法向量。&lt;/p&gt;
&lt;p&gt;类似地，当 &lt;span class="math"&gt;\(x\in \mathbf{R}^3\)&lt;/span&gt; 时，感知机模型满足空间中的平面方程：&lt;/p&gt;
&lt;div class="math"&gt;$$ix^{(1)}+jx^{(2)}+kx^{(3)}+b=0$$&lt;/div&gt;
&lt;p&gt;且 &lt;span class="math"&gt;\(w=(i,j,k)^\mathrm{T}\)&lt;/span&gt; 为平面法向量。&lt;/p&gt;
&lt;p&gt;因此，感知机在模型本质上是在特征空间 &lt;span class="math"&gt;\(\mathbf{R}^n\)&lt;/span&gt; 中的一个超平面 &lt;span class="math"&gt;\(S\)&lt;/span&gt;，代表特征向量的点被超平面 &lt;span class="math"&gt;\(S\)&lt;/span&gt; 分隔成两部分，其中参数 &lt;span class="math"&gt;\(w\)&lt;/span&gt; 为超平面法向量。&lt;/p&gt;
&lt;p&gt;&lt;img alt="感知机的几何模型" src="https://storage.live.com/items/4D18B16B8E0B1EDB!7509?authkey=ALYpzW-ZQ_VBXTU"/&gt;&lt;/p&gt;
&lt;p&gt;超平面 &lt;span class="math"&gt;\(S\)&lt;/span&gt; 也应符合 &lt;span class="math"&gt;\(\mathbf{R}^n\)&lt;/span&gt; 空间中的几何关系，所以在 &lt;span class="math"&gt;\(\mathbf{R}^n\)&lt;/span&gt; 空间中的任意一点 &lt;span class="math"&gt;\(x_0\)&lt;/span&gt; 到超平面的距离为&lt;/p&gt;
&lt;div class="math"&gt;$$d=\frac{1}{||w||}|w\cdot x_0+b|$$&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(||w||\)&lt;/span&gt; 是 &lt;span class="math"&gt;\(w\)&lt;/span&gt; 的 &lt;span class="math"&gt;\(L_2\)&lt;/span&gt; 范数：&lt;/p&gt;
&lt;div class="math"&gt;$$||w||=\sqrt{\sum(w_i)^2}$$&lt;/div&gt;
&lt;p&gt;即法向量长度。&lt;/p&gt;
&lt;h4&gt;点到超平面距离公式的推导&lt;/h4&gt;
&lt;p&gt;以 &lt;span class="math"&gt;\(x\in \mathbf{R}^2\)&lt;/span&gt; 为例，将超平面 &lt;span class="math"&gt;\(S\)&lt;/span&gt; 方程转化为截距式：&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{align}
     ix^{(1)}+jx^{(2)}+b&amp;amp;=0\\
     \frac{x^{(1)}}{-\frac{b}{i}}+\frac{x^{(2)}}{-\frac{b}{j}}&amp;amp;=1
\end{align}$$&lt;/div&gt;
&lt;p&gt;超平面 &lt;span class="math"&gt;\(S\)&lt;/span&gt; 在 &lt;span class="math"&gt;\(x^{(2)}\)&lt;/span&gt; 轴上的截距就为 &lt;span class="math"&gt;\(-\frac{b}{j}\)&lt;/span&gt;。过点 &lt;span class="math"&gt;\(x_0\)&lt;/span&gt; 作平行于 &lt;span class="math"&gt;\(S\)&lt;/span&gt; 的超平面 &lt;span class="math"&gt;\(S_0\)&lt;/span&gt;，同样得到截距式：&lt;/p&gt;
&lt;div class="math"&gt;$$\frac{x^{(1)}}{-\frac{b_0}{i}}+\frac{x^{(2)}}{-\frac{b_0}{j}}=1$$&lt;/div&gt;
&lt;p&gt;超平面 &lt;span class="math"&gt;\(S_0\)&lt;/span&gt; 在 &lt;span class="math"&gt;\(x^{(2)}\)&lt;/span&gt; 轴上的截距为 &lt;span class="math"&gt;\(-\frac{b_0}{j}\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img alt="示意图" src="https://storage.live.com/items/4D18B16B8E0B1EDB!7517?authkey=ALYpzW-ZQ_VBXTU"/&gt;&lt;/p&gt;
&lt;p&gt;将 &lt;span class="math"&gt;\(d\)&lt;/span&gt; 平移至蓝色三角形中，&lt;span class="math"&gt;\(\boldsymbol{w}\)&lt;/span&gt; 是超平面的法向量，&lt;span class="math"&gt;\(\boldsymbol{w}=w=(i,j)^\mathrm{T}\)&lt;/span&gt;，根据向量夹角余弦公式&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{align}
    \cos\theta&amp;amp;=|\cos(\boldsymbol{w},\boldsymbol{j})|\\
    &amp;amp;=\frac{|\boldsymbol{w}\cdot\boldsymbol{j}|}{|\boldsymbol{w}||\boldsymbol{j}|}
\end{align}$$&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\boldsymbol{j}\)&lt;/span&gt; 为 &lt;span class="math"&gt;\(x^{(2)}\)&lt;/span&gt; 方向的单位向量，因此有&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{align}
    \cos\theta&amp;amp;=\frac{|(i,j)^\mathrm{T}\cdot(0,1)^\mathrm{T}|}{|\boldsymbol{w}|}\\
    &amp;amp;=\frac{|j|}{|\boldsymbol{w}|}
\end{align}$$&lt;/div&gt;
&lt;p&gt;在蓝色三角形中，&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{align}
    d&amp;amp;=\left|\frac{b}{j}-\frac{b_0}{j}\right|\cos\theta\\
    &amp;amp;=\frac{|b-b_0|}{|j|}\frac{|j|}{|\boldsymbol{w}|}\\
    &amp;amp;=\frac{|b-b_0|}{|\boldsymbol{w}|}\\
\end{align}$$&lt;/div&gt;
&lt;p&gt;由 &lt;span class="math"&gt;\(w\cdot x_0+b_0=0\)&lt;/span&gt; 得到 &lt;span class="math"&gt;\(b_0=-w\cdot x_0\)&lt;/span&gt;，代入就可以证得&lt;/p&gt;
&lt;div class="math"&gt;$$d=\frac{|w\cdot x_0+b|}{||w||}$$&lt;/div&gt;
&lt;h2 id="gan-zhi-ji-xue-xi-ce-lue_1"&gt;感知机学习策略&lt;/h2&gt;
&lt;p&gt;感知机的分类情况可以归为以下几类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(w\cdot x_i+b\geqslant0\)&lt;/span&gt;,&lt;span class="math"&gt;\(\ y_i=+1\)&lt;/span&gt;，分类正确；&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(w\cdot x_i+b\geqslant0\)&lt;/span&gt;,&lt;span class="math"&gt;\(\ y_i=-1\)&lt;/span&gt;，分类错误；&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(w\cdot x_i+b&amp;lt;0\)&lt;/span&gt;,&lt;span class="math"&gt;\(\ y_i=-1\)&lt;/span&gt;，分类正确；&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(w\cdot x_i+b&amp;lt;0\)&lt;/span&gt;,&lt;span class="math"&gt;\(\ y_i=+1\)&lt;/span&gt;，分类错误。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此分类错误的数据点 &lt;span class="math"&gt;\((x_i,y_i)\)&lt;/span&gt; 满足&lt;/p&gt;
&lt;div class="math"&gt;$$-y_i(w\cdot x_i+b)&amp;gt;0$$&lt;/div&gt;
&lt;p&gt;若超平面 &lt;span class="math"&gt;\(S\)&lt;/span&gt; 误分类的点的集合为 &lt;span class="math"&gt;\(M\)&lt;/span&gt;，那么误分类点到超平面的距离之和为&lt;/p&gt;
&lt;div class="math"&gt;$$\sum_{x_i\in M}\left[-\frac{1}{||w||}y_i(w\cdot x_i+b)\right]$$&lt;/div&gt;
&lt;p&gt;略去 &lt;span class="math"&gt;\(\frac{1}{||w||}\)&lt;/span&gt;（见第七章），得到&lt;em&gt;经验风险函数&lt;/em&gt;：&lt;/p&gt;
&lt;div class="math"&gt;$$L(w,b)=-\sum_{x_i\in M}y_i(w\cdot x_i+b)$$&lt;/div&gt;
&lt;p&gt;感知机的学习策略就是在假设空间中选取 &lt;span class="math"&gt;\(L(w,b)\)&lt;/span&gt; 最小的模型参数 &lt;span class="math"&gt;\(w\)&lt;/span&gt; 和 &lt;span class="math"&gt;\(b\)&lt;/span&gt;。&lt;/p&gt;
&lt;h2 id="gan-zhi-ji-xue-xi-suan-fa"&gt;感知机学习算法&lt;/h2&gt;
&lt;p&gt;感知机的学习算法就是求解以下最优化问题的算法：&lt;/p&gt;
&lt;div class="math"&gt;$$\min_{w,b}L(w,b)=-\sum_{x_i\in M}y_i(w\cdot x_i+b)$$&lt;/div&gt;
&lt;h3 id="sui-ji-ti-du-xia-jiang-fa"&gt;随机梯度下降法&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;任意选取超平面 &lt;span class="math"&gt;\(w_0\cdot x+b_0=0\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;随机选取误分类点使 &lt;span class="math"&gt;\(L(w,b)\)&lt;/span&gt; 梯度下降；&lt;/li&gt;
&lt;li&gt;不断更新 &lt;span class="math"&gt;\(w\)&lt;/span&gt; 与 &lt;span class="math"&gt;\(b\)&lt;/span&gt;，直至 &lt;span class="math"&gt;\(L(w,b)=0\)&lt;/span&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;二元函数 &lt;span class="math"&gt;\(f(x,y)\)&lt;/span&gt; 在 &lt;span class="math"&gt;\((x_0,y_0)\)&lt;/span&gt; 处的梯度定义为&lt;/p&gt;
&lt;div class="math"&gt;$$\mathbf{grad}\ f(x_0,y_0)=\nabla f(x_0,y_0)=f_x(x_0,y_0)\boldsymbol{i}+f_y(x_0,y_0)\boldsymbol{j}$$&lt;/div&gt;
&lt;p&gt;因此损失函数 &lt;span class="math"&gt;\(L(w,b)\)&lt;/span&gt; 的梯度为&lt;/p&gt;
&lt;div class="math"&gt;$$\nabla_wL(w,b)=\frac{\partial\left[-\sum_{x_i\in M}\color{teal}{y_i}(w\cdot \color{teal}{x_i}+b)\right]}{\partial w}=-\sum_{x_i\in M}\color{teal}{y_ix_i}$$&lt;/div&gt;
&lt;div class="math"&gt;$$\nabla_bL(w,b)=\frac{\partial\left[-\sum_{x_i\in M}\color{teal}{y_i}(w\cdot x_i+b)\right]}{\partial b}=-\sum_{x_i\in M}\color{teal}{y_i}$$&lt;/div&gt;
&lt;p&gt;随机选择误分类点 &lt;span class="math"&gt;\((x_i,y_i)\)&lt;/span&gt; 更新 &lt;span class="math"&gt;\(w\)&lt;/span&gt; 与 &lt;span class="math"&gt;\(b\)&lt;/span&gt;，使 &lt;span class="math"&gt;\(L(w,b)\)&lt;/span&gt; 沿梯度方向下降：&lt;/p&gt;
&lt;div class="math"&gt;$$w\leftarrow w+\eta y_ix_i$$&lt;/div&gt;
&lt;div class="math"&gt;$$b\leftarrow b+\eta y_i$$&lt;/div&gt;
&lt;p&gt;其中 &lt;span class="math"&gt;\(\eta\ (0&amp;lt;\eta\leqslant1)\)&lt;/span&gt; 称为步长，不断迭代至 &lt;span class="math"&gt;\(L(w,b)=0\)&lt;/span&gt;。&lt;/p&gt;
&lt;h3 id="gan-zhi-ji-yuan-shi-xing-shi-suan-fa"&gt;感知机原始形式算法&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;算法2.1&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;设定步长 &lt;span class="math"&gt;\(\eta\)&lt;/span&gt;，选取初值 &lt;span class="math"&gt;\(w_0\)&lt;/span&gt; 与 &lt;span class="math"&gt;\(b_0\)&lt;/span&gt;，一般为 &lt;span class="math"&gt;\(w_0=0\)&lt;/span&gt;，&lt;span class="math"&gt;\(b_0=0\)&lt;/span&gt;；&lt;/li&gt;
&lt;li&gt;选取点 &lt;span class="math"&gt;\((x_i,y_i)\)&lt;/span&gt;；&lt;/li&gt;
&lt;li&gt;若 &lt;span class="math"&gt;\(y_i(w\cdot x_i+b)\leqslant0\)&lt;/span&gt;，&lt;div class="math"&gt;$$w\leftarrow w+\eta y_ix_i$$&lt;/div&gt;
&lt;div class="math"&gt;$$b\leftarrow b+\eta y_i$$&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;重复步骤（2），直至没有误分类点，即 &lt;span class="math"&gt;\(L(w,b)=0\)&lt;/span&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="gan-zhi-ji-dui-ou-xing-shi-suan-fa"&gt;感知机对偶形式算法&lt;/h3&gt;
&lt;p&gt;经过数次以下迭代步骤：&lt;/p&gt;
&lt;div class="math"&gt;$$w\leftarrow w+\eta y_ix_i$$&lt;/div&gt;
&lt;div class="math"&gt;$$b\leftarrow b+\eta y_i$$&lt;/div&gt;
&lt;p&gt;&lt;em&gt;最终的&lt;/em&gt; &lt;span class="math"&gt;\(w\)&lt;/span&gt; 和 &lt;span class="math"&gt;\(b\)&lt;/span&gt; 可以表示为&lt;/p&gt;
&lt;div class="math"&gt;$$w=\sum_{i=1}^N \alpha_iy_ix_i$$&lt;/div&gt;
&lt;div class="math"&gt;$$b=\sum_{i=1}^N\alpha_iy_i$$&lt;/div&gt;
&lt;p&gt;其中 &lt;span class="math"&gt;\(\alpha_i=n_i\eta\)&lt;/span&gt;，&lt;span class="math"&gt;\(n_i\)&lt;/span&gt; 表示点 &lt;span class="math"&gt;\((x_i,y_i)\)&lt;/span&gt; 被误分类的次数。也就是说，在迭代的每一次过程中，被误分类的点 &lt;span class="math"&gt;\((x_i,y_i)\)&lt;/span&gt; 都不断向超平面靠近，直至位于超平面的另一侧。&lt;/p&gt;
&lt;p&gt;最后得到的感知机模型应为&lt;/p&gt;
&lt;div class="math"&gt;$$f(x)=\mathrm{sign}\left(\sum_{i=1}^N\alpha_iy_ix_i\cdot x+b\right)$$&lt;/div&gt;
&lt;p&gt;为了与 &lt;span class="math"&gt;\(x=x_i\)&lt;/span&gt; 代入后的模型相区别，表示为&lt;/p&gt;
&lt;div class="math"&gt;$$f(x)=\mathrm{sign}\left(\sum_{j=1}^N\alpha_jy_jx_j\cdot x+b\right)$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;算法2.2&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;设定步长 &lt;span class="math"&gt;\(\eta\)&lt;/span&gt;，选取初值 &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; 与 &lt;span class="math"&gt;\(b_0\)&lt;/span&gt;，一般为 &lt;span class="math"&gt;\(\alpha=(\alpha_1,\alpha_2,\cdots,\alpha_N)^\mathrm{T}=0\)&lt;/span&gt;，&lt;span class="math"&gt;\(b_0=0\)&lt;/span&gt;；&lt;/li&gt;
&lt;li&gt;选取点 &lt;span class="math"&gt;\((x_i,y_i)\)&lt;/span&gt;；&lt;/li&gt;
&lt;li&gt;若&lt;span class="math"&gt;\(y_i\left(\sum_{j=1}^N\alpha_jy_jx_j\cdot x_i+b\right)\leqslant0\)&lt;/span&gt;，&lt;div class="math"&gt;$$\alpha_i\leftarrow\alpha_i+\eta$$&lt;/div&gt;
&lt;div class="math"&gt;$$b\leftarrow b+\eta y_i$$&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;重复步骤（2），直至没有误分类点。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;考虑迭代的判断条件&lt;/p&gt;
&lt;div class="math"&gt;$$y_i\left(\sum_{j=1}^N\alpha_jy_j\vec{x_j}\cdot \vec{x_i}+b\right)\leqslant0$$&lt;/div&gt;
&lt;p&gt;每次判断都需要计算&lt;/p&gt;
&lt;div class="math"&gt;$$\sum_{j=1}^N\alpha_jy_j\color{teal}{\vec{x_j}\cdot \vec{x_i}}=\alpha_1y_1\color{teal}{\vec{x_1}\cdot\vec{x_i}}+\alpha_2y_2\color{teal}{\vec{x_2}\cdot\vec{x_i}}+\cdots+\alpha_Ny_N\color{teal}{\vec{x_N}\cdot\vec{x_i}}$$&lt;/div&gt;
&lt;p&gt;因此可以将内积以矩阵形式存放，即 Gram 矩阵：&lt;/p&gt;
&lt;div class="math"&gt;$$\boldsymbol{G}=[x_i\cdot x_j]_{N\times N}=\begin{bmatrix}
    x_1\cdot x_1 &amp;amp;\cdots &amp;amp;x_1\cdot x_N\\
    \vdots       &amp;amp;\ddots &amp;amp;\vdots\\
    x_N\cdot x_1 &amp;amp;\cdots &amp;amp;x_N\cdot x_N
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;由于内积的性质，Gram 矩阵实际上是一个对称矩阵。&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="references_1"&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://book.douban.com/subject/33437381/"&gt;李航, 2019. 统计学习方法（第2版）. 清华大学出版社.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="碎碎念"></category><category term="《统计学习方法》"></category><category term="机器学习"></category></entry><entry><title>《统计学习方法》第一章</title><link href="http://localhost:8000/blog03.html" rel="alternate"></link><published>2022-07-21T00:00:00+08:00</published><updated>2022-07-21T00:00:00+08:00</updated><author><name>Leo</name></author><id>tag:localhost,2022-07-21:/blog03.html</id><summary type="html">&lt;p&gt;统计学习及监督学习概论&lt;/p&gt;</summary><content type="html">&lt;h2 id="ji-ben-gai-nian"&gt;基本概念&lt;/h2&gt;
&lt;h3 id="tong-ji-xue-xi-guo-cheng"&gt;统计学习过程&lt;/h3&gt;
&lt;p&gt;统计学习主要基于数据概率构建概率统计模型并运用模型分析和预测数据，统计学习的主要过程可以归纳为：&lt;/p&gt;
&lt;div class="math"&gt;$$\boxed{\frac{训练数据集}{T=\{(x_i,y_i)\}}}\stackrel{学习}{\Longrightarrow}\boxed{\frac{模型}{P(Y|X)\ \mathrm{or}\ Y=f(X)}}\stackrel{预测}{\Longrightarrow}y_{N+1}$$&lt;/div&gt;
&lt;p&gt;其中，训练集表示为：&lt;/p&gt;
&lt;div class="math"&gt;$$
T=\{ (x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N) \}
$$&lt;/div&gt;
&lt;p&gt;其中输入变量 &lt;span class="math"&gt;\(X\)&lt;/span&gt; 的取值 &lt;span class="math"&gt;\(x_i\)&lt;/span&gt; 为特征向量：&lt;/p&gt;
&lt;div class="math"&gt;$$
x_i=(x^{(1)}_i,x^{(2)}_i,\cdots,x^{(n)}_i)^\mathrm{T}
$$&lt;/div&gt;
&lt;p&gt;输入变量 &lt;span class="math"&gt;\(X\)&lt;/span&gt; 与输出变量 &lt;span class="math"&gt;\(Y\)&lt;/span&gt; 遵循联合概率分布 &lt;span class="math"&gt;\(P(X,Y)\)&lt;/span&gt;，经过学习得到的模型可以是概率模型 &lt;span class="math"&gt;\(P(Y|X)\)&lt;/span&gt;，也可以是非概率模型 &lt;span class="math"&gt;\(Y=f(X)\)&lt;/span&gt;。&lt;/p&gt;
&lt;h3 id="gai-lu-mo-xing-yu-fei-gai-lu-mo-xing"&gt;概率模型与非概率模型&lt;/h3&gt;
&lt;p&gt;在监督学习中，概率模型为条件概率分布形式 &lt;span class="math"&gt;\(P(y|x)\)&lt;/span&gt;，非概率模型为决策函数形式 &lt;span class="math"&gt;\(y=f(x)\)&lt;/span&gt;；在无监督学习中，概率模型为 &lt;span class="math"&gt;\(P(z|x)\)&lt;/span&gt; 或 &lt;span class="math"&gt;\(P(x|z)\)&lt;/span&gt;，非概率模型为隐函数形式 &lt;span class="math"&gt;\(z=g(x)\)&lt;/span&gt;。&lt;/p&gt;
&lt;div class="math"&gt;$$P(y|x)\underset{归一化}{\overset{最大化}{\rightleftharpoons}} y=f(x)$$&lt;/div&gt;
&lt;p&gt;由于 &lt;span class="math"&gt;\(P(y|x)\)&lt;/span&gt; 与 &lt;span class="math"&gt;\(y=f(x)\)&lt;/span&gt; 可以按照上述过程转化，所以概率模型与非概率模型不仅仅是在表现形式存在差异，更为重要的是在内部结构上，概率模型的变量、参数符合一定的联合概率分布，这也决定了概率模型符合以下基本概率公式：&lt;/p&gt;
&lt;div class="math"&gt;$$P(x)=\sum_y P(x,y)$$&lt;/div&gt;
&lt;div class="math"&gt;$$P(x,y)=P(x)P(y|x)$$&lt;/div&gt;
&lt;h2 id="tong-ji-xue-xi-fang-fa-san-yao-su_1"&gt;统计学习方法三要素&lt;/h2&gt;
&lt;h3 id="mo-xing"&gt;模型&lt;/h3&gt;
&lt;p&gt;模型就是需要学习的条件分布概率或决策函数，由假设模型构成的集合称为假设空间，可以表示为：&lt;/p&gt;
&lt;div class="math"&gt;$$\mathcal{F}=\{f|Y=f_\theta(X),\theta\in\mathbf{R}^n\}$$&lt;/div&gt;
&lt;p&gt;或&lt;/p&gt;
&lt;div class="math"&gt;$$\mathcal{F}=\{P|P_\theta(Y|X),\theta\in\mathbf{R}^n\}$$&lt;/div&gt;
&lt;p&gt;其中 &lt;span class="math"&gt;\(\theta\)&lt;/span&gt; 为模型的参数向量，&lt;span class="math"&gt;\(\mathbf{R}^n\)&lt;/span&gt; 称为参数空间。&lt;/p&gt;
&lt;h3 id="ce-lue"&gt;策略&lt;/h3&gt;
&lt;p&gt;在假设空间中选择最优模型的方法称之为策略。&lt;/p&gt;
&lt;h4&gt;损失函数和风险函数&lt;/h4&gt;
&lt;p&gt;用损失函数能够衡量模型预测值 &lt;span class="math"&gt;\(f(X)\)&lt;/span&gt; 与真实值 &lt;span class="math"&gt;\(Y\)&lt;/span&gt; 的差距，从而评估模型的优劣。损失函数记作 &lt;span class="math"&gt;\(L(Y,f(X))\)&lt;/span&gt;，例如常见的平方损失函数定义为：&lt;/p&gt;
&lt;div class="math"&gt;$$L(Y,f(X))=(Y-f(X))^2$$&lt;/div&gt;
&lt;p&gt;输入变量 &lt;span class="math"&gt;\(X\)&lt;/span&gt; 与输出变量 &lt;span class="math"&gt;\(Y\)&lt;/span&gt; 遵循联合概率分布 &lt;span class="math"&gt;\(P(X,Y)\)&lt;/span&gt;，损失函数的期望为：&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{align}
    R_{\mathrm{exp}}(f)&amp;amp;=E_P[L(Y,f(X))]\\
    &amp;amp;= \int_{\mathcal{X}\times\mathcal{Y}}L(y,f(x))P(x,y)\mathrm{d}x\mathrm{d}y\\
\end{align}$$&lt;/div&gt;
&lt;p&gt;该期望就是模型 &lt;span class="math"&gt;\(f(X)\)&lt;/span&gt; 在联合分布 &lt;span class="math"&gt;\(P(X,Y)\)&lt;/span&gt; 平均意义下的损失，称为风险函数。但由于 &lt;span class="math"&gt;\(P(X,Y)\)&lt;/span&gt; 无法确定，风险函数也无法计算，因此定义了能够确定的经验风险。经验风险是模型 &lt;span class="math"&gt;\(f(X)\)&lt;/span&gt; 在训练集 &lt;span class="math"&gt;\(T\)&lt;/span&gt; 中的平均损失：&lt;/p&gt;
&lt;div class="math"&gt;$$R_{\mathrm{rmp}}(f)=\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))$$&lt;/div&gt;
&lt;p&gt;当样本容量 &lt;span class="math"&gt;\(N\)&lt;/span&gt; 趋向于无穷时，经验风险 &lt;span class="math"&gt;\(R_{\mathrm{rmp}}\)&lt;/span&gt; 趋于期望风险 &lt;span class="math"&gt;\(R_{\mathrm{exp}}\)&lt;/span&gt;&lt;/p&gt;
&lt;h4&gt;经验风险最小化与结构风险最小化&lt;/h4&gt;
&lt;p&gt;经验风险最小化策略通过寻找经验风险最小的模型作为最优模型，经验风险最小化策略需要足够大的样本容量，否则容易出现过拟合。经验风险最小化策本质为求解最优化问题：&lt;/p&gt;
&lt;div class="math"&gt;$$\min_{f\in\mathcal{F}}\frac{1}{N}L(y_i,f(x_i))$$&lt;/div&gt;
&lt;p&gt;结构风险最小化策略是防止过拟合的策略，其本质为求解最优化问题：&lt;/p&gt;
&lt;div class="math"&gt;$$\min_{f\in\mathcal{F}}\frac{1}{N}L(y_i,f(x_i))+\lambda J(f)$$&lt;/div&gt;
&lt;p&gt;其中 &lt;span class="math"&gt;\(J(f)\)&lt;/span&gt; 是模型的复杂度，表示对复杂模型的惩罚，&lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; 为系数。&lt;/p&gt;
&lt;h3 id="suan-fa"&gt;算法&lt;/h3&gt;
&lt;p&gt;算法是学习模型的具体计算方法。&lt;/p&gt;
&lt;h2 id="fan-hua_1"&gt;泛化&lt;/h2&gt;
&lt;h3 id="fan-hua-wu-chai"&gt;泛化误差&lt;/h3&gt;
&lt;p&gt;泛化能力是学习得到的模型对未知数据的预测能力，学习得到的模型对未知项进行预测的误差称为泛化误差，泛化误差等同于模型 &lt;span class="math"&gt;\(\hat{f}\)&lt;/span&gt; 的期望风险：&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{align}
    R_{\mathrm{exp}}(\hat{f})&amp;amp;=E_P[L(Y,\hat{f}(X))]\\
    &amp;amp;= \int_{\mathcal{X}\times\mathcal{Y}}L(y,\hat{f}(x))P(x,y)\mathrm{d}x\mathrm{d}y\\
\end{align}$$&lt;/div&gt;
&lt;h3 id="er-fen-lei-wen-ti-de-fan-hua-wu-chai-shang-jie"&gt;二分类问题的泛化误差上界&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;定理 1.1&lt;/strong&gt; 对于二分类问题，当假设空间是有限个函数的集合
 &lt;span class="math"&gt;\(\mathcal{F}=\{ f_1,f_2,\cdots,f_d\}\)&lt;/span&gt; 时，对任意一个函数 &lt;span class="math"&gt;\(f\in \mathcal{F}\)&lt;/span&gt;，至少以概率 &lt;span class="math"&gt;\(1-\delta\)&lt;/span&gt;，&lt;span class="math"&gt;\(0&amp;lt;\delta&amp;lt;1\)&lt;/span&gt;，以下不等式成立（证明见参考）：&lt;/p&gt;
&lt;div class="math"&gt;$$R(f)\leq\hat{R}(f)+\varepsilon(d,N,\delta)$$&lt;/div&gt;
&lt;div class="math"&gt;$$\varepsilon(d,N\delta)=\sqrt{\frac{1}{2N}(\log d+\log\frac{1}{\delta})}$$&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(R(f)\)&lt;/span&gt; 为泛化误差，&lt;span class="math"&gt;\(\hat{R}(f)\)&lt;/span&gt; 为训练误差。&lt;/p&gt;
&lt;p&gt;泛化误差上界的性质：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;样本容量增加，泛化上界趋于0；&lt;/li&gt;
&lt;li&gt;假设空间越大，泛化上界越大。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="jian-du-xue-xi-de-ying-yong_1"&gt;监督学习的应用&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;输入变量 X&lt;/th&gt;
&lt;th&gt;输出变量 Y&lt;/th&gt;
&lt;th&gt;问题&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;离散变量&lt;/td&gt;
&lt;td&gt;分类&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;变量序列&lt;/td&gt;
&lt;td&gt;变量序列&lt;/td&gt;
&lt;td&gt;标注&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;连续变量&lt;/td&gt;
&lt;td&gt;连续变量&lt;/td&gt;
&lt;td&gt;回归&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr/&gt;
&lt;h2 id="references"&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://book.douban.com/subject/33437381/"&gt;李航, 2019. 统计学习方法（第2版）. 清华大学出版社.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.cnblogs.com/pastispast/p/12589078.html"&gt;二分类问题泛化误差上界的详细证明 - p_is_p - 博客园&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="碎碎念"></category><category term="《统计学习方法》"></category><category term="机器学习"></category></entry><entry><title>将 OneDrive 作为博客图床</title><link href="http://localhost:8000/blog02.html" rel="alternate"></link><published>2022-07-14T00:00:00+08:00</published><updated>2022-07-14T00:00:00+08:00</updated><author><name>Leo</name></author><id>tag:localhost,2022-07-14:/blog02.html</id><summary type="html">&lt;p&gt;在 Linux 上使用 ZFile 管理 OneDrive 文件，利用 Microsoft API 生成图片链接&lt;/p&gt;</summary><content type="html">&lt;p&gt;在个人博客中，图片是不可或缺的，而生成图片的直链后才能在&lt;code&gt;.md&lt;/code&gt;文件中使用，因此通常又需要图床等额外工具。由于国内市场的图床工具良莠不齐，没有精力仔细挑选，还有就是把数据交在他们的手中多少有些不放心。想到订阅 Microsoft Office 时附赠了 1 TB 的 OneDrive 容量，正好可以利用起来。使用 OneDrive 作为图床的好处就在于数据在自己的手中，不用担心某天突然挂掉，还有就是在多平台（Windows、iPad 和 Android）都有 OneDrive 应用，很方便同步。但是很遗憾，由于国内的环境，OneDrive 的网页版是打不开的，这就不能通过网页版直接生成图片链接，必须『绕道通行』。&lt;/p&gt;
&lt;p&gt;Windows 系统自带 OneDrive 应用，可以直接使用桌面应用进行文件同步，借助 &lt;a href="https://github.com/Richasy/Img-Share"&gt;Img Share&lt;/a&gt; 生成图片链接。Img Share 后来被 &lt;a href="https://apps.microsoft.com/store/detail/picture-share/9PHWZ3QL0HN3?hl=en-us&amp;amp;gl=US"&gt;Picture Share&lt;/a&gt; 代替，在 Microsoft Store 中就可以直接下载到。Picture Share 十分容易上手，界面简洁且功能齐全，具体的设置方法可以参考&lt;a href="https://wzblog.fun/posts/b036879a/"&gt;这篇文章&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;但是写博客的工作环境是 Linux 系统，Linux 系统中没有 OneDrive 应用和上述 UWP 应用，也就不能使用上面的方法。本文就将介绍如何在 Linux 系统下使用 OneDrive 作为个人博客的图床并使用ZFile同步云盘文件。&lt;/p&gt;
&lt;h2 id="onedrive-wen-jian-lian-jie-de-sheng-cheng-fang-shi"&gt;OneDrive 文件链接的生成方式&lt;/h2&gt;
&lt;p&gt;OneDrive 的网页应用直接提供了嵌入代码，可以直接贴在文章中。但因为科学上网时上传速度相当感人，使用起来还是太过麻烦。虽然无法访问 OneDrive 网页，但 OneDrive 在国内的其他功能都是正常的，包括生成的分享链接，所以直接借用官方API生成链接的方案是可行的。发现有人已经写好了&lt;a href="https://github.com/harrisoff/onedrive-image-hosting"&gt;相关项目&lt;/a&gt;，点开项目右侧的链接登录自己的OneDrive后直接插入&lt;code&gt;.md&lt;/code&gt;就可以啦。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;![图片名称](https://api.onedrive.com/v1.0/shares/s!AtseC45rsRhNuUZNJKuT3c_gI4Jh/root/content)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="an-zhuang-zfile"&gt;安装 ZFile&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/zhaojun1998/zfile"&gt;ZFile&lt;/a&gt; 是一款在线网盘程序，支持包括 OneDrive 在内的多种存储源。ZFile 可以代替其他平台的 OneDrive 应用来管理云盘中的文件，实现同步、上传、下载等功能。ZFile 也能生成文件直链插入文章，但是这个功能需要云服务器，抱着能省则省的态度，就等以后再折腾，这里仅使用 ZFile 来管理 OneDrive。&lt;/p&gt;
&lt;p&gt;在 Linux 系统使用 ZFile 首先需要安装依赖：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Debian 10&lt;/span&gt;
apt update &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt install -y apt-transport-https software-properties-common ca-certificates dirmngr gnupg
wget -qO - https://adoptopenjdk.jfrog.io/adoptopenjdk/api/gpg/key/public &lt;span class="p"&gt;|&lt;/span&gt; apt-key add -
add-apt-repository --yes https://adoptopenjdk.jfrog.io/adoptopenjdk/deb/
apt update &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt install -y adoptopenjdk-8-hotspot-jre
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;下载 ZFile：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;ZFILE_INSTALL_PATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;~/zfile
mkdir -p &lt;span class="nv"&gt;$ZFILE_INSTALL_PATH&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;cd&lt;/span&gt; &lt;span class="nv"&gt;$ZFILE_INSTALL_PATH&lt;/span&gt;
wget https://c.jun6.net/ZFILE/zfile-release.war
unzip zfile-release.war &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; rm -rf zfile-release.war
chmod +x &lt;span class="nv"&gt;$ZFILE_INSTALL_PATH&lt;/span&gt;/bin/*.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;ZFILE_INSTALL_PATH&lt;/code&gt;指定了安装路径，可以自行修改。&lt;/p&gt;
&lt;h2 id="qi-dong-bing-pei-zhi-zfile"&gt;启动并配置 ZFile&lt;/h2&gt;
&lt;p&gt;通过以下命令启动 ZFile：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt; ~/zfile/bin/start.sh       &lt;span class="c1"&gt;# 启动项目&lt;/span&gt;
 ~/zfile/bin/stop.sh        &lt;span class="c1"&gt;# 停止项目&lt;/span&gt;
 ~/zfile/bin/restart.sh     &lt;span class="c1"&gt;# 重启项目&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;启动项目后，默认开放在 8080 端口，使用&lt;code&gt;localhost:8080&lt;/code&gt;进入 ZFile：
&lt;img alt="注册/登录界面" src="https://api.onedrive.com/v1.0/shares/s!AtseC45rsRhNuUeZko02sAbyr5jh/root/content"/&gt;首次开启时需要注册管理员账号，登录进入系统后，首先配置存储源，选择存储策略为&lt;code&gt;OneDrive&lt;/code&gt;，启用文件操作。
&lt;img alt="配置存储源" src="https://api.onedrive.com/v1.0/shares/s!AtseC45rsRhNuUUBsSGYxpEV6Frp/root/content"/&gt;点击链接登录 OneDrive 账号获取令牌，填写完成后即可保存设置。&lt;img alt="获取令牌" src="https://api.onedrive.com/v1.0/shares/s!AtseC45rsRhNuUPS4i5g5F_-nR4T/root/content"/&gt;设置成功后在存储源中就可以看见 OneDrive 标志，并且显示刷新成功，这样 ZFile 就已经正常工作了。&lt;img alt="存储源列表" src="https://api.onedrive.com/v1.0/shares/s!AtseC45rsRhNuUSMlwPi40T-1Um4/root/content"/&gt;&lt;/p&gt;
&lt;h2 id="shi-yong-zfile-guan-li-onedrive"&gt;使用 ZFile 管理 OneDrive&lt;/h2&gt;
&lt;p&gt;在地址栏中输入&lt;code&gt;localhost:8080&lt;/code&gt;进入存储界面，在这里就理应能够看到 OneDrive 中存储的文件了，可以使用其他设备辅助测试是否能够正常上传或删除文件。&lt;/p&gt;
&lt;p&gt;如果有一台 VPS，在 VPS 上启动 ZFile 后，通过&lt;code&gt;vps-ip:[port]&lt;/code&gt;也能进入同样的管理界面。只需要将图片文件上传至 OneDrive，使用ZFile就可以得到文件的直链，不止是图片，这种方法还可以在&lt;code&gt;.md&lt;/code&gt;中插入音频或是视频文件，甚至搭建个人下载站，而且完全不占用服务器存储。值得注意的是，ZFile获得的文件『直链』并不是真正的直链，而是经过一次转发，可能会影响访问速度。&lt;img alt="ZFile获取直链流程" src="https://storage.live.com/items/4D18B16B8E0B1EDB!7369?authkey=ALYpzW-ZQ_VBXTU"/&gt;因为 ZFile 向 OneDrive 请求得到是预览链接或临时下载链接&lt;code&gt;1drv.com/...&lt;/code&gt;，该链接在一段时间后就会失效，也不能直接用作图床。当用户每次访问ZFile直链&lt;code&gt;vps-ip:[port]/...&lt;/code&gt;时，实际得到的都是Z File 转发得到的 OneDrive 临时链接。&lt;/p&gt;</content><category term="碎碎念"></category><category term="blog"></category><category term="OneDrive"></category></entry><entry><title>使用 Pelican 发布文章的流程</title><link href="http://localhost:8000/blog01.html" rel="alternate"></link><published>2022-07-12T00:00:00+08:00</published><updated>2022-07-12T00:00:00+08:00</updated><author><name>Leo</name></author><id>tag:localhost,2022-07-12:/blog01.html</id><summary type="html">&lt;p&gt;如何使用 Pelican 在搭建在 Github Pages 上的博客发布文章&lt;/p&gt;</summary><content type="html">&lt;h2 id="articles-or-pages"&gt;Articles or pages?&lt;/h2&gt;
&lt;p&gt;Pelican 中有 articles 与 pages 的概念，在创建页面时应当首先区分二者。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;articles&lt;/strong&gt; 指具有时间戳的内容，例如博客文章等，直接创建在&lt;code&gt;content&lt;/code&gt;文件夹中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pages&lt;/strong&gt; 指与时间无关、展示固定内容的页面，需要创建在&lt;code&gt;content/pages&lt;/code&gt;文件夹下&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="zhuan-xie-wen-zhang"&gt;撰写文章&lt;/h2&gt;
&lt;h3 id="jupyter-notebook-fang-shi"&gt;Jupyter Notebook 方式&lt;/h3&gt;
&lt;p&gt;Jupyter Notebook 能够保存下代码的输入与输出信息，特别适合用于展示程序输出的图形。首先在&lt;code&gt;content&lt;/code&gt;目录中创建&lt;code&gt;.nbdata&lt;/code&gt;与&lt;code&gt;.ipynb&lt;/code&gt;的同名文件。&lt;code&gt;.nbdata&lt;/code&gt;文件中保存了文章的结构信息，而&lt;code&gt;.ipynb&lt;/code&gt;使用 Jupyter Notebook 保存了文章的具体内容。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;title: # 文章标题
slug: # 文章地址
date: # 时间
category: # 类别
tags: # 标签
author: # 作者
summary: # 概要

# 其他不常用信息
modified: # 修改时间
keywords: # 仅用于html内容
authors: # 多作者
lang: # 语言
translation: # 是否属于译文
status: # draft, hidden, or published
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="markdown-fang-shi"&gt;Markdown 方式&lt;/h3&gt;
&lt;p&gt;使用 Markdown 语言是写博客最为简单普遍的方式，在&lt;code&gt;content&lt;/code&gt;文件夹中创建&lt;code&gt;.md&lt;/code&gt;文件，在开始部分首先输入与&lt;code&gt;.nbdata&lt;/code&gt;相同的文章信息后，就可以直接开始撰写正文。&lt;/p&gt;
&lt;h2 id="sheng-cheng-jing-tai-wang-ye_1"&gt;生成静态网页&lt;/h2&gt;
&lt;p&gt;在撰写文章后，进入虚拟环境，在&lt;code&gt;blog&lt;/code&gt;文件夹中使用&lt;code&gt;Pelican&lt;/code&gt;生成&lt;code&gt;.html&lt;/code&gt;文件。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;source&lt;/span&gt; ./venv/bin/activate
pelican content -s publishconf.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;最后将&lt;code&gt;output&lt;/code&gt;文件夹同步至 Github 中&lt;code&gt;&amp;lt;username&amp;gt;.github.io&lt;/code&gt;仓库即完成文章的发布。&lt;/p&gt;
&lt;h2 id="fa-bu"&gt;发布&lt;/h2&gt;
&lt;p&gt;使用终端在&lt;code&gt;output&lt;/code&gt;文件夹中输入&lt;code&gt;python -m pelican.server&lt;/code&gt;可以开启本地服务器，默认端口为 8000，通过&lt;code&gt;localhost:8000&lt;/code&gt;访问。&lt;/p&gt;
&lt;p&gt;测试完成后将内容推送至 Github:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git add .
git commit
git push
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="ke-long-yu-tong-bu"&gt;克隆与同步&lt;/h2&gt;
&lt;p&gt;由于我有 Windows 与 Linux 两个平台的设备，所以需要在两个平台上同步博客的内容，方便我在任意设备上都可以写文章。&lt;/p&gt;
&lt;p&gt;在终端中使用&lt;code&gt;git clone --recursive&lt;/code&gt;命令克隆仓库，&lt;code&gt;git clone&lt;/code&gt;命令只会克隆主仓库，导致子模块失效，&lt;code&gt;--recursive&lt;/code&gt;能递归地克隆包括子模块在内的整个仓库。使用&lt;code&gt;git pull --recurse-submodules&lt;/code&gt;命令能够拉取包含子模块在内的全部更新，即可完成同步。&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="references"&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.getpelican.com/en/latest/settings.html"&gt;Pelican Settings Document&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zodiac911.github.io/blog/static-blog.html#%E7%B3%BB%E7%BB%9F%E8%A6%81%E6%B1%82"&gt;Pelican + GitHubPages 搭建个人博客 &amp;middot; Zodiac Wang&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="碎碎念"></category><category term="blog"></category><category term="Pelican"></category></entry></feed>